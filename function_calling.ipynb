{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fucntion calling\n",
    "\n",
    "![function-calling flow chart](./imgs/flow-chart.svg)\n",
    "\n",
    "| Step | Executor   | Key Action                     | Data Format Example                                           |\n",
    "| :--- | :--------- | :----------------------------- | :------------------------------------------------------------ |\n",
    "| 1    | Application | Send user input + function definitions | `{\"messages\":[...], \"functions\":[...]}`                      |\n",
    "| 2    | Large Model | Decide response method         | Generate `tool_calls` or respond directly                     |\n",
    "| 3    | Large Model | Return function call           | `{\"tool_calls\": [{\"name\": \"func\", \"arguments\": {...}}]}`     |\n",
    "| 4    | Application | Execute local function         | Parse arguments and invoke `func(**args)`                    |\n",
    "| 5    | Application | Submit execution result        | `{\"tool_call_id\": \"...\", \"role\": \"tool\", \"content\": \"result\"}` |\n",
    "\n",
    "Chinese vesion:\n",
    "| 步骤 | 执行方 | 关键动作              | 数据格式示例                                                 |\n",
    "| :--- | :----- | :-------------------- | :----------------------------------------------------------- |\n",
    "| 1    | 应用   | 发送用户输入+函数定义 | `{\"messages\":[...], \"functions\":[...]}`                      |\n",
    "| 2    | 大模型 | 决策响应方式          | 生成`tool_calls`或 直接回答                                   |\n",
    "| 3    | 大模型 | 返回函数调用          | `{\"tool_calls\": [{\"name\": \"func\", \"arguments\": {...}}]}`     |\n",
    "| 4    | 应用   | 执行本地函数          | 解析参数并调用`func(**args)`                                 |\n",
    "| 5    | 应用   | 提交执行结果          | `{\"tool_call_id\": \"...\", \"role\": \"tool\", \"content\": \"result\"}` |\n",
    "\n",
    "step 5 is optional\n",
    "\n",
    "addional flowchart to understand it better\n",
    "\n",
    " <img src=\"./imgs/flow-chart2.svg\" alt=\"Flow Chart\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location):\n",
    "    return \"24℃\"\n",
    "available_functions = {\"get_weather\": get_weather}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def send_messages(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    return response.choices[0].message\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get weather of an location, the user shoud supply a location first\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User>\t How's the weather in Hangzhou?\n",
      "model response with tool_to_call: ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0_47c3cbc2-1a7d-444f-9f86-a367822ce9ae', function=Function(arguments='{\"location\":\"Hangzhou\"}', name='get_weather'), type='function', index=0)])\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"How's the weather in Hangzhou?\"}]\n",
    "message = send_messages(messages)\n",
    "messages.append(message)\n",
    "print(f\"User>\\t {messages[0]['content']}\")\n",
    "print(f\"model response with tool_to_call\\n: {message}\")\n",
    "\n",
    "tool = message.tool_calls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察上面打印的LLM结果，其中`content`为空，`tool_calls`不空，表示LLM告诉我们下一步需要调用对应的tools。相反，如果LLM返回的是直接结果，则content不空，tool_calls为空。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessageToolCall(id='call_0_47c3cbc2-1a7d-444f-9f86-a367822ce9ae', function=Function(arguments='{\"location\":\"Hangzhou\"}', name='get_weather'), type='function', index=0)\n",
      "get_weather\n",
      "{\"location\":\"Hangzhou\"}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(tool)\n",
    "print(tool.function.name)\n",
    "print(tool.function.arguments)\n",
    "print(type(tool.function.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24℃'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "function_name = available_functions[tool.function.name]\n",
    "function_args = json.loads(tool.function.arguments)\n",
    "function_response = function_name(**function_args) #call the function\n",
    "function_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么要传 `tool_call_id`： 可能会涉及到多个tool的调用，为了让LLM匹配哪个tool的结果是什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model>\t The current weather in Hangzhou is 24°C. It's a pleasant temperature!\n"
     ]
    }
   ],
   "source": [
    " #append the function response into the messages, which will be sent to the model to let model know the result of the tool\n",
    "messages.append({\"role\": \"tool\", \"tool_call_id\": tool.id, \"content\": function_response})\n",
    "message = send_messages(messages)\n",
    "print(f\"Model>\\t {message.content}\") \n",
    "messages.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"How's the weather in Hangzhou?\"},\n",
       " ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0_47c3cbc2-1a7d-444f-9f86-a367822ce9ae', function=Function(arguments='{\"location\":\"Hangzhou\"}', name='get_weather'), type='function', index=0)]),\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'call_0_47c3cbc2-1a7d-444f-9f86-a367822ce9ae',\n",
       "  'content': '24℃'},\n",
       " ChatCompletionMessage(content=\"The current weather in Hangzhou is 24°C. It's a pleasant temperature!\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
